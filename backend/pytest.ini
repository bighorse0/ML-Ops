[tool:pytest]
# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output and reporting
addopts = 
    --verbose
    --tb=short
    --strict-markers
    --disable-warnings
    --color=yes
    --durations=10
    --maxfail=5
    --cov=api
    --cov=services
    --cov=models
    --cov=utils
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --junitxml=test-results.xml
    --html=test-report.html
    --self-contained-html

# Markers
markers =
    unit: Unit tests
    integration: Integration tests
    api: API endpoint tests
    slow: Slow running tests
    database: Tests that require database
    auth: Authentication tests
    permissions: Permission tests
    validation: Validation tests
    search: Search and filtering tests
    monitoring: Monitoring tests
    computation: Computation tests
    lineage: Lineage tests
    users: User management tests
    organizations: Organization tests
    features: Feature management tests
    feature_values: Feature values tests

# Test configuration
minversion = 6.0
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning

# Environment variables for testing
env =
    TESTING = true
    DATABASE_URL = sqlite+aiosqlite:///:memory:
    REDIS_URL = redis://localhost:6379/1
    KAFKA_BOOTSTRAP_SERVERS = localhost:9092
    SECRET_KEY = test-secret-key-for-testing-only
    ALGORITHM = HS256
    ACCESS_TOKEN_EXPIRE_MINUTES = 30
    API_KEY_HEADER = X-API-Key
    CORS_ORIGINS = ["http://localhost:3000"]
    TRUSTED_HOSTS = ["localhost", "127.0.0.1"]
    LOG_LEVEL = DEBUG
    RATE_LIMIT_PER_MINUTE = 100
    RATE_LIMIT_PER_HOUR = 1000
    RATE_LIMIT_PER_DAY = 10000
    STORAGE_TYPE = local
    STORAGE_PATH = ./test_storage
    MONITORING_ENABLED = true
    PROMETHEUS_ENABLED = true
    COMPUTATION_ENGINE = local
    COMPUTATION_WORKERS = 2
    COMPUTATION_TIMEOUT = 300

# Coverage configuration
[coverage:run]
source = api,services,models,utils
omit = 
    */tests/*
    */migrations/*
    */__pycache__/*
    */venv/*
    */env/*
    setup.py

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod

# Test data configuration
[test_data]
# Sample data for testing
sample_feature_data = {
    "name": "test_feature",
    "description": "Test feature for testing",
    "data_type": "float",
    "feature_type": "numeric",
    "entity_type": "user",
    "serving_mode": "online",
    "storage_type": "postgresql",
    "tags": ["test", "feature"],
    "metadata": {"test": True}
}

sample_feature_value_data = {
    "feature_id": 1,
    "entity_id": "test_entity",
    "value": "test_value",
    "timestamp": "2023-01-01T00:00:00Z"
}

sample_user_data = {
    "email": "test@example.com",
    "username": "testuser",
    "password": "secure_password123",
    "first_name": "Test",
    "last_name": "User",
    "role": "user"
}

sample_organization_data = {
    "name": "Test Organization",
    "description": "Test organization for testing",
    "domain": "test.example.com"
}

sample_data_quality_data = {
    "feature_id": 1,
    "metric_type": "completeness",
    "value": 0.95,
    "threshold": 0.9,
    "status": "pass"
}

sample_performance_data = {
    "feature_id": 1,
    "metric_type": "latency",
    "value": 100,
    "unit": "ms"
}

sample_alert_rule_data = {
    "name": "Test Alert Rule",
    "description": "Test alert rule for testing",
    "metric_type": "data_quality",
    "condition": "less_than",
    "threshold": 0.9,
    "severity": "medium"
}

sample_computation_job_data = {
    "name": "Test Job",
    "description": "Test computation job",
    "job_type": "batch",
    "priority": "medium",
    "config": {}
}

sample_pipeline_data = {
    "name": "Test Pipeline",
    "description": "Test computation pipeline",
    "pipeline_type": "feature_engineering",
    "config": {}
}

sample_task_data = {
    "name": "Test Task",
    "description": "Test computation task",
    "task_type": "transform",
    "config": {}
}

sample_result_data = {
    "job_id": 1,
    "task_id": 1,
    "result_type": "feature_values",
    "data": {}
}

sample_feature_lineage_data = {
    "feature_id": 1,
    "source_type": "dataset",
    "source_id": "test_dataset",
    "transformation_type": "aggregation"
}

sample_data_lineage_data = {
    "source_dataset": "test_source",
    "target_dataset": "test_target",
    "transformation_type": "aggregation"
}

sample_lineage_node_data = {
    "node_id": "test_node",
    "node_type": "feature",
    "name": "Test Node"
}

sample_lineage_edge_data = {
    "source_node_id": "source_node",
    "target_node_id": "target_node",
    "edge_type": "derives_from"
} 